{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2207047a",
   "metadata": {},
   "source": [
    "# End-To-End NLP: Question Answering \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df36b9ad",
   "metadata": {},
   "source": [
    "## Overview  \n",
    "\n",
    "End-to-End NLP material is designed from a real-world perspective that follows the data processing, development, and deployment pipeline paradigm. The material consists of three labs and the goal is to walk you through a single flow of raw text `data preprocessing` and how to build a SQuAD dataset format for Question Answering, train the dataset via `NVIDIA® NeMo Megatron` and `NVIDIA TAO Toolkit`, and deploy using `RIVA`. Furthermore, a challenge notebook is introduced to test your understanding of the material and solidify your experience in the Question Answering (QA) domain.\n",
    "\n",
    "\n",
    "### Why End-to-End NLP?\n",
    "\n",
    "Solving real-world problems in the AI domain requires the use of a set of tools (software stacks and frameworks) and the solution process always follows the `data processing`, `development`, and `deployment` pattern. This material is to:\r\n",
    "- assist AI hackathon participants to learn and apply the knowledge to solve their tasks using NVIDIA software stacks and frameworks\r\n",
    "- enables bootcamp attendees to solve real-world problem using end-to-end approach (data processing --> development --> deployment)\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da574ea",
   "metadata": {},
   "source": [
    "The table of content below will walk you through the QA phases and the Exercise included will test your understanding of the concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2155fe9c",
   "metadata": {},
   "source": [
    "### Table of Content\n",
    "\n",
    "The following contents will be covered:\n",
    "1. Data preprocessing\n",
    "    1. Overview of QA Dataset\n",
    "        1. Introduction to QA\n",
    "        1. Brief on QA Dataset\n",
    "    1. Common Preprocessing Techniques for Raw Text Data\n",
    "    1. QA Text Data preprocessing\n",
    "        1. SQuAD Dataset Structural Format\n",
    "        1. Text Data Source   \n",
    "        1. Mannual QA Extraction\n",
    "        1. Automatic QA Generation with T5 model\n",
    "    1. Exercise\n",
    "    1. Summary\n",
    "1. Development\n",
    "    1. Question Answering Training and Fine-Tuning\n",
    "1. Deployment\n",
    "    1. RIVA Deployment \n",
    "    1. Challenge\n",
    "1. NeMo Megatron-GPT\n",
    "    1. [Nemo Fundamentals](jupyter_notebook/nemo/NeMo_Primer.ipynb)\n",
    "    1. [Question Answering](jupyter_notebook/nemo/Question_Answering.ipynb)\n",
    "    1. [Prompt Tuning/P-Tuning](jupyter_notebook/nemo/Multitask_Prompt_and_PTuning.ipynb)   \n",
    "    1. [NeMo Megatron-GPT 1.3B: Language Model Inferencing](jupyter_notebook/nemo/demo.ipynb)\n",
    "    1. [Challenge](jupyter_notebook/nemo/Challenge_cuad.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd58974e",
   "metadata": {},
   "source": [
    "### Check your GPU\n",
    "\n",
    "Let's execute the cell below to display information about the CUDA driver and GPUs running on the server by running the nvidia-smi command. To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting `Ctrl-Enter`, or pressing the play button in the toolbar above. If all goes well, you should see some output returned below the grey cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7821889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3702768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start_Here.ipynb\n",
      "data/\n",
      "data/speech/\n",
      "data/speech/audio_question_2.wav\n",
      "data/speech/audio_question_1.wav\n",
      "data/.ipynb_checkpoints/\n",
      "jupyter_notebook/\n",
      "jupyter_notebook/question-answering-training.ipynb\n",
      "jupyter_notebook/qa-riva-deployment.ipynb\n",
      "jupyter_notebook/Summary.ipynb\n",
      "jupyter_notebook/Overview.ipynb\n",
      "jupyter_notebook/images/\n",
      "jupyter_notebook/images/haystack_csv_file.png\n",
      "jupyter_notebook/images/sheet2.png\n",
      "jupyter_notebook/images/nq_paper.PNG\n",
      "jupyter_notebook/images/source_data_raw.PNG\n",
      "jupyter_notebook/images/haystack_adding_question.png\n",
      "jupyter_notebook/images/haystack_create_project3.png\n",
      "jupyter_notebook/images/squad_tigram_prefixes.png\n",
      "jupyter_notebook/images/excel_sample.png\n",
      "jupyter_notebook/images/sample_application.png\n",
      "jupyter_notebook/images/haystack_homepage.png\n",
      "jupyter_notebook/images/infer.png\n",
      "jupyter_notebook/images/source_data_doc.png\n",
      "jupyter_notebook/images/qa_model_riva.png\n",
      "jupyter_notebook/images/haystack_2.png\n",
      "jupyter_notebook/images/source_data_excel.png\n",
      "jupyter_notebook/images/rmir.png\n",
      "jupyter_notebook/images/riva_export.png\n",
      "jupyter_notebook/images/haystack_question_list.png\n",
      "jupyter_notebook/images/haystack_create_project.png\n",
      "jupyter_notebook/images/coqa_paper.png\n",
      "jupyter_notebook/images/qa-model_riva.png\n",
      "jupyter_notebook/images/haystack_3.png\n",
      "jupyter_notebook/images/haystack_signup.png\n",
      "jupyter_notebook/images/riva_quickstart_v26.png\n",
      "jupyter_notebook/images/haystack_1.png\n",
      "jupyter_notebook/images/ngc_key.jpg\n",
      "jupyter_notebook/images/haystack_create_project2.png\n",
      "jupyter_notebook/images/end-to-end-arch.jpg\n",
      "jupyter_notebook/images/folder_structure.png\n",
      "jupyter_notebook/images/ngc_signin.jpg\n",
      "jupyter_notebook/images/squad_format.png\n",
      "jupyter_notebook/images/application-flow.jpg\n",
      "jupyter_notebook/images/riva_models.png\n",
      "jupyter_notebook/images/sheet0.png\n",
      "jupyter_notebook/images/squad_paper.png\n",
      "jupyter_notebook/images/sheet1.png\n",
      "jupyter_notebook/images/ngccli_installation.jpg\n",
      "jupyter_notebook/images/QA_illustration.png\n",
      "jupyter_notebook/images/download_cli.jpg\n",
      "jupyter_notebook/images/models_list_folders.png\n",
      "jupyter_notebook/images/haystack_text_upload.png\n",
      "jupyter_notebook/images/coqa_tigram_prefixes.png\n",
      "jupyter_notebook/images/export_riva.png\n",
      "jupyter_notebook/images/haystack_general_question.png\n",
      "jupyter_notebook/images/spec.png\n",
      "jupyter_notebook/images/ngc_setup.jpg\n",
      "jupyter_notebook/General_preprocessing.ipynb\n",
      "jupyter_notebook/Exercise.ipynb\n",
      "jupyter_notebook/challenge.ipynb\n",
      "jupyter_notebook/nemo/\n",
      "jupyter_notebook/nemo/Question_Answering.ipynb\n",
      "jupyter_notebook/nemo/Solution_cuad.ipynb\n",
      "jupyter_notebook/nemo/images/\n",
      "jupyter_notebook/nemo/images/gpt_arc_openai.jpg\n",
      "jupyter_notebook/nemo/images/thutmose_tagger_final_alignment.png\n",
      "jupyter_notebook/nemo/images/thutmose_tagger_alignment_top.png\n",
      "jupyter_notebook/nemo/images/thutmose_tagger_architecture.png\n",
      "jupyter_notebook/nemo/images/NeMo_technique.png\n",
      "jupyter_notebook/nemo/images/gpt_arc_original.png\n",
      "jupyter_notebook/nemo/images/prompt_learning_forward_pass.png\n",
      "jupyter_notebook/nemo/images/thutmose_tagger_tag_vocabulary.png\n",
      "jupyter_notebook/nemo/images/BRAT_example.JPG\n",
      "jupyter_notebook/nemo/images/NeMo_Framework.png\n",
      "jupyter_notebook/nemo/images/nmt_data_pipeline.png\n",
      "jupyter_notebook/nemo/images/thutmose_tagger_alignment_bottom.png\n",
      "jupyter_notebook/nemo/NeMo_Primer.ipynb\n",
      "jupyter_notebook/nemo/Start_megatron_gpt_1_3B_server.txt\n",
      "jupyter_notebook/nemo/Challenge_cuad.ipynb\n",
      "jupyter_notebook/nemo/demo.ipynb\n",
      "jupyter_notebook/nemo/Multitask_Prompt_and_PTuning.ipynb\n",
      "jupyter_notebook/nemo/.ipynb_checkpoints/\n",
      "jupyter_notebook/nemo/.ipynb_checkpoints/Question_Answering-checkpoint.ipynb\n",
      "jupyter_notebook/nemo/.ipynb_checkpoints/demo-checkpoint.ipynb\n",
      "jupyter_notebook/nemo/.ipynb_checkpoints/NeMo_Primer-checkpoint.ipynb\n",
      "jupyter_notebook/nemo/.ipynb_checkpoints/Challenge_cuad-checkpoint.ipynb\n",
      "jupyter_notebook/nemo/.ipynb_checkpoints/demo_github-checkpoint.ipynb\n",
      "jupyter_notebook/nemo/.ipynb_checkpoints/Start_megatron_gpt_1_3B_server-checkpoint.txt\n",
      "jupyter_notebook/nemo/.ipynb_checkpoints/Multitask_Prompt_and_PTuning-checkpoint.ipynb\n",
      "jupyter_notebook/nemo/.ipynb_checkpoints/Solution_cuad-checkpoint.ipynb\n",
      "jupyter_notebook/.ipynb_checkpoints/\n",
      "jupyter_notebook/.ipynb_checkpoints/qa-riva-deployment-checkpoint.ipynb\n",
      "jupyter_notebook/.ipynb_checkpoints/Exercise-checkpoint.ipynb\n",
      "jupyter_notebook/.ipynb_checkpoints/Overview-checkpoint.ipynb\n",
      "jupyter_notebook/.ipynb_checkpoints/challenge-checkpoint.ipynb\n",
      "jupyter_notebook/.ipynb_checkpoints/=-checkpoint\n",
      "jupyter_notebook/.ipynb_checkpoints/question-answering-training-checkpoint.ipynb\n",
      "jupyter_notebook/.ipynb_checkpoints/General_preprocessing-checkpoint.ipynb\n",
      "jupyter_notebook/.ipynb_checkpoints/QandA_data_processing-checkpoint.ipynb\n",
      "jupyter_notebook/.ipynb_checkpoints/Summary-checkpoint.ipynb\n",
      "jupyter_notebook/QandA_data_processing.ipynb\n",
      "results/\n",
      "results/nemo_question_answering/\n",
      "results/challenge_ptuning/\n",
      "results/challenge/\n",
      "results/challenge/export_riva/\n",
      "results/challenge/export_riva/ignore.txt\n",
      "results/questions_answering/\n",
      "results/questions_answering/export_riva/\n",
      "results/.ipynb_checkpoints/\n",
      "source_code/\n",
      "source_code/nemo_question_answering/\n",
      "source_code/nemo_question_answering/get_squad.py\n",
      "source_code/nemo_question_answering/conf/\n",
      "source_code/nemo_question_answering/conf/qa_conf.yaml\n",
      "source_code/challenge_quickstart/\n",
      "source_code/challenge_quickstart/nemo2riva-2.6.0-py3-none-any.whl\n",
      "source_code/challenge_quickstart/riva_start_client.sh\n",
      "source_code/challenge_quickstart/riva_start.sh\n",
      "source_code/challenge_quickstart/riva_clean.sh\n",
      "source_code/challenge_quickstart/config.sh\n",
      "source_code/challenge_quickstart/asr_lm_tools/\n",
      "source_code/challenge_quickstart/asr_lm_tools/tune_LM_flashlight.sh\n",
      "source_code/challenge_quickstart/asr_lm_tools/config_LM_tuning_gpu_decoder.sh\n",
      "source_code/challenge_quickstart/asr_lm_tools/config_LM_tuning_flashlight_decoder.sh\n",
      "source_code/challenge_quickstart/asr_lm_tools/config_LM_tuning.sh\n",
      "source_code/challenge_quickstart/asr_lm_tools/modify_config_param.sh\n",
      "source_code/challenge_quickstart/asr_lm_tools/tune_LM.sh\n",
      "source_code/challenge_quickstart/riva_init.sh\n",
      "source_code/challenge_quickstart/protos/\n",
      "source_code/challenge_quickstart/protos/riva_nlp.proto\n",
      "source_code/challenge_quickstart/protos/riva_asr.proto\n",
      "source_code/challenge_quickstart/protos/riva_tts.proto\n",
      "source_code/challenge_quickstart/protos/riva_audio.proto\n",
      "source_code/challenge_quickstart/protos/health.proto\n",
      "source_code/challenge_quickstart/riva_stop.sh\n",
      "source_code/challenge_quickstart/.ipynb_checkpoints/\n",
      "source_code/challenge_quickstart/.ipynb_checkpoints/config-checkpoint.sh\n",
      "source_code/challenge_quickstart/.ipynb_checkpoints/riva_start-checkpoint.sh\n",
      "source_code/challenge_quickstart/.ipynb_checkpoints/riva_init-checkpoint.sh\n",
      "source_code/dataset_cuad.py\n",
      "source_code/prompt_learning_cuad_preprocessing.py\n",
      "source_code/challenge_ptuning/\n",
      "source_code/challenge_ptuning/megatron_gpt_prompt_learning_eval.py\n",
      "source_code/challenge_ptuning/conf/\n",
      "source_code/challenge_ptuning/conf/megatron_gpt_prompt_learning_inference.yaml\n",
      "source_code/challenge_ptuning/conf/megatron_gpt_prompt_learning_config.yaml\n",
      "source_code/challenge_ptuning/conf/.ipynb_checkpoints/\n",
      "source_code/challenge_ptuning/conf/.ipynb_checkpoints/megatron_gpt_prompt_learning_config-checkpoint.yaml\n",
      "source_code/megatron-gpt-model.py\n",
      "source_code/data/\n",
      "source_code/data/ecommerce.csv\n",
      "source_code/data/Climatechange.docx\n",
      "source_code/data/QA_ds.csv\n",
      "source_code/data/custom_squad.json\n",
      "source_code/data/answers.json\n",
      "source_code/data/Amazon Product Dataset  2020summary.txt\n",
      "source_code/data/QA_ds.xlsx\n",
      "source_code/data/ecommerce_data_kaggle.txt\n",
      "source_code/data/1806.03822.pdf\n",
      "source_code/data/ecommerce_1.csv\n",
      "source_code/data/marketing_sample_for_amazon_com-ecommerce__20200101_20200131__10k_data.csv_home_sdf_marketing_sample_for_amazon_com-ecommerce__20200101_20200131__10k_data.csv\n",
      "source_code/riva_quickstart_v2.6.0/\n",
      "source_code/riva_quickstart_v2.6.0/nemo2riva-2.6.0-py3-none-any.whl\n",
      "source_code/riva_quickstart_v2.6.0/riva_start_client.sh\n",
      "source_code/riva_quickstart_v2.6.0/riva_start.sh\n",
      "source_code/riva_quickstart_v2.6.0/riva_clean.sh\n",
      "source_code/riva_quickstart_v2.6.0/config.sh\n",
      "source_code/riva_quickstart_v2.6.0/asr_lm_tools/\n",
      "source_code/riva_quickstart_v2.6.0/asr_lm_tools/tune_LM_flashlight.sh\n",
      "source_code/riva_quickstart_v2.6.0/asr_lm_tools/config_LM_tuning_gpu_decoder.sh\n",
      "source_code/riva_quickstart_v2.6.0/asr_lm_tools/config_LM_tuning_flashlight_decoder.sh\n",
      "source_code/riva_quickstart_v2.6.0/asr_lm_tools/config_LM_tuning.sh\n",
      "source_code/riva_quickstart_v2.6.0/asr_lm_tools/modify_config_param.sh\n",
      "source_code/riva_quickstart_v2.6.0/asr_lm_tools/tune_LM.sh\n",
      "source_code/riva_quickstart_v2.6.0/riva_init.sh\n",
      "source_code/riva_quickstart_v2.6.0/protos/\n",
      "source_code/riva_quickstart_v2.6.0/protos/riva_nlp.proto\n",
      "source_code/riva_quickstart_v2.6.0/protos/riva_asr.proto\n",
      "source_code/riva_quickstart_v2.6.0/protos/riva_tts.proto\n",
      "source_code/riva_quickstart_v2.6.0/protos/riva_audio.proto\n",
      "source_code/riva_quickstart_v2.6.0/protos/health.proto\n",
      "source_code/riva_quickstart_v2.6.0/riva_stop.sh\n",
      "source_code/riva_quickstart_v2.6.0/riva_api-2.1.0-py3-none-any.whl\n",
      "source_code/riva_quickstart_v2.6.0/.ipynb_checkpoints/\n",
      "source_code/riva_quickstart_v2.6.0/.ipynb_checkpoints/config-checkpoint.sh\n",
      "source_code/riva_quickstart_v2.6.0/.ipynb_checkpoints/riva_start-checkpoint.sh\n",
      "source_code/riva_quickstart_v2.6.0/.ipynb_checkpoints/riva_init-checkpoint.sh\n",
      "source_code/conf/\n",
      "source_code/conf/megatron_gpt_prompt_learning_config.yaml\n",
      "source_code/conf/.ipynb_checkpoints/\n",
      "source_code/conf/.ipynb_checkpoints/megatron_gpt_prompt_learning_config-checkpoint.yaml\n",
      "source_code/dataset.py\n",
      "source_code/prompt_learning_squad_preprocessing.py\n",
      "source_code/.ipynb_checkpoints/\n",
      "source_code/.ipynb_checkpoints/prompt_learning_cuad_preprocessing-checkpoint.py\n",
      "source_code/.ipynb_checkpoints/dataset_cuad-checkpoint.py\n",
      "source_code/.ipynb_checkpoints/dataset-checkpoint.py\n"
     ]
    }
   ],
   "source": [
    "!tar chvfz notebook.tar.hz *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a5a23",
   "metadata": {},
   "source": [
    "### Tutorial Duration\n",
    "\n",
    "The material will be presented 4 labs in a total of 8hrs sessions (without the challenge) as follows:\n",
    "- Data preprocessing Lab: `1hrs`\n",
    "- Development and Deployment Labs: `3hrs`\n",
    "- NeMo Megatron-GPT : `4hrs`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0f0aac",
   "metadata": {},
   "source": [
    "### Content Level\n",
    "Beginner to Advanced\n",
    "\n",
    "### Target Audience and Prerequisites\r\n",
    "The target audience for these labs are researchers, graduate students, and developers who are interested in the End-to-End approach to solving NLP tasks via the use of GPUs. Audiences are expected to have Python programming background Knowledge and possess NVIDIA NGC key\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9836cc8e",
   "metadata": {},
   "source": [
    "---\n",
    "## Licensing\n",
    "\n",
    "Copyright © 2022 OpenACC-Standard.org. This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
